# NaughtyGPT


This repo serves as a collection on information on exploiting modern LLMs through a variety of different techniques such as prompt injection, poisoning, jailbreaking and more.

Currently only has [Gandalf](https://gandalf.lakera.ai/) solutions but I am planning on adding more LLM exploits in the coming months!
